{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss 0.0000, test_loss 0.0000\n",
      "epoch 2, train_loss 0.0000, test_loss 0.0000\n",
      "epoch 3, train_loss 0.0000, test_loss 0.0000\n",
      "epoch 4, train_loss 0.0000, test_loss 0.0000\n",
      "epoch 5, train_loss 0.0000, test_loss 0.0000\n",
      "epoch 6, train_loss 0.0000, test_loss 0.0000\n",
      "epoch 7, train_loss 0.0000, test_loss 0.0000\n",
      "epoch 8, train_loss 0.0000, test_loss 0.0000\n",
      "epoch 9, train_loss 0.0000, test_loss 0.0000\n",
      "epoch 10, train_loss 0.0000, test_loss 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "\n",
    "# 获取数据集\n",
    "batch_size = 100\n",
    "feature_size = 200\n",
    "def genMultiNormalData(mean, train_num, test_num, label):\n",
    "    \n",
    "    # 样本特征x的维度为200\n",
    "    train_mean = mean\n",
    "    \n",
    "    # 协方差矩阵\n",
    "    cov = np.eye(feature_size)\n",
    "    train_size = (train_num, 1)\n",
    "    test_size = (test_num, 1)\n",
    "    \n",
    "    # 生成训练集\n",
    "    train_result = np.random.multivariate_normal(mean, cov, train_size)\n",
    "    train_result = np.squeeze(train_result)\n",
    "\n",
    "    # 生成测试集\n",
    "    test_result = np.random.multivariate_normal(mean, cov, test_size)\n",
    "    test_result = np.squeeze(test_result)\n",
    "    \n",
    "    train_labels = None\n",
    "    test_labels = None\n",
    "    \n",
    "    # 生成标签\n",
    "    if label == 0:\n",
    "        train_labels = np.zeros(train_num)\n",
    "        test_labels = np.zeros(test_num)\n",
    "    else:\n",
    "        train_labels = np.ones(train_num)\n",
    "        test_labels = np.ones(test_num)\n",
    "    return train_result, train_labels, test_result, test_labels\n",
    "\n",
    "# 生成数据集1\n",
    "mean = [i for i in range(1, 1+feature_size)]\n",
    "x1_mean = torch.tensor(mean)\n",
    "x1_train, x1_train_labels, x1_test, x1_test_labels = genMultiNormalData(x1_mean, 7000, 3000, 0)\n",
    "\n",
    "# 生成数据集2\n",
    "x2_mean = -1 * x1_mean\n",
    "x2_train, x2_train_labels, x2_test, x2_test_labels = genMultiNormalData(x2_mean, 7000, 3000, 1)\n",
    "\n",
    "x_train = np.append(x1_train, x2_train, axis = 0)\n",
    "x_train_labels = np.append(x1_train_labels, x2_train_labels, axis = 0)\n",
    "x_test = np.append(x1_test, x2_test, axis = 0)\n",
    "x_test_labels = np.append(x1_test_labels, x2_test_labels, axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_train_labels = torch.from_numpy(x_train_labels).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "x_test_labels = torch.from_numpy(x_test_labels).float()\n",
    "\n",
    "# plt.figure(figsize=(12,8))\n",
    "# plt.scatter(x_test[:, 0], x_test[:, 1],\n",
    "#             c = x_test_labels, alpha = .4)\n",
    "\n",
    "\n",
    "# 把数据放在数据库中\n",
    "torch_dataset_x_train = Data.TensorDataset(x_train, x_train_labels)\n",
    "torch_dataset_x_test = Data.TensorDataset(x_test, x_test_labels)\n",
    "\n",
    "# 分批次吐数据\n",
    "train_iter = Data.DataLoader(\n",
    "    # 从数据库中每次抽出batch size个样本\n",
    "    dataset=torch_dataset_x_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "test_iter = Data.DataLoader(\n",
    "    # 从数据库中每次抽出batch size个样本\n",
    "    dataset=torch_dataset_x_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "# print('x_test.shape', x_test.shape)\n",
    "# print('x_test_labels.shape', x_test_labels.shape)\n",
    "# print('x_train.shape', x_test.shape)\n",
    "# print('x_train.shape', x_test_labels.shape)\n",
    "\n",
    "# 定义模型参数\n",
    "num_epochs = 10\n",
    "lr = 0.1\n",
    "num_inputs, num_outputs = feature_size, 1\n",
    "\n",
    "W1 = torch.tensor(np.random.normal(0, 0.01, (num_outputs, num_inputs)), dtype=torch.double)\n",
    "b1 = torch.zeros(num_outputs, dtype=torch.double)\n",
    "\n",
    "# print('W1', W1)\n",
    "params = [W1, b1]\n",
    "for param in params:\n",
    "    param.requires_grad_(requires_grad=True)\n",
    "\n",
    "# 定义模型\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(num_inputs, num_outputs),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "    \n",
    "# 定义损失函数\n",
    "loss = torch.nn.BCELoss()\n",
    "\n",
    "# 定义优化函数\n",
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad\n",
    "        \n",
    "optimizer =torch.optim.SGD(net.parameters(), lr)\n",
    "        \n",
    "# 计算模型在数据集上的准确率\n",
    "def evaluate_accuracy(data_iter, net, loss):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    test_l_sum = 0.0\n",
    "    for X, y in data_iter:\n",
    "#         acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        l = loss(net(X).squeeze(), y).sum()\n",
    "        test_l_sum += l.item()\n",
    "        n += y.shape[0]\n",
    "        return acc_sum / n, test_l_sum / n\n",
    "\n",
    "# 定义模型训练参数\n",
    "def train(net, train_iter, test_iter, loss, num_epochs, batch_size, params=None, lr=None, optimizer=None):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_acc_sum, train_l_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X).squeeze()\n",
    "            l = loss(y_hat, y).sum()\n",
    "            \n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                SGD(params, lr)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                \n",
    "            train_l_sum += l.item()\n",
    "#             print('y_hat.shape', y_hat.shape)\n",
    "#             print('y.shape', y.shape)\n",
    "#             train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc, test_l = evaluate_accuracy(test_iter, net, loss)\n",
    "        train_loss.append(train_l_sum/n)\n",
    "        test_loss.append(test_l)\n",
    "       \n",
    "        print('epoch %d, train_loss %.4f, test_loss %.4f' % (epoch + 1, train_l_sum / n, test_l))\n",
    "    return train_loss, test_loss\n",
    "\n",
    "\n",
    "\n",
    "train_loss, test_loss = train(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr, optimizer)\n",
    "\n",
    "#画图\n",
    "x = np.linspace(0, len(train_loss), len(train_loss))\n",
    "plt.plot(x, train_loss, label = 'train_loss', linewidth=1.5)\n",
    "plt.plot(x, test_loss, label='test_loss', linewidth = 1.5)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
